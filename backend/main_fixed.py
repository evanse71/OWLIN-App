from fastapi import FastAPI, File, UploadFile, HTTPException
from fastapi.middleware.cors import CORSMiddleware
import os
import uuid
import re
import sys
from datetime import datetime
from pathlib import Path
from typing import Dict, Any, List, Optional
import logging

# Add backend to path for imports
sys.path.insert(0, os.path.dirname(os.path.abspath(__file__)))

# Import analytics routes
try:
    from routes.analytics import router as analytics_router
except ImportError:
    # If analytics routes aren't available, create a dummy router
    from fastapi import APIRouter
    analytics_router = APIRouter(prefix="/analytics", tags=["analytics"])
    
    @analytics_router.get("/dashboard")
    async def get_dashboard_analytics():
        return {"message": "Analytics not available in this server"}

# Import document queue routes
try:
    from routes.document_queue import router as document_queue_router
except ImportError:
    # If document queue routes aren't available, create a dummy router
    from fastapi import APIRouter
    document_queue_router = APIRouter(prefix="/documents", tags=["documents"])
    
    @document_queue_router.get("/queue")
    async def get_documents_for_review():
        return {"documents": []}

# Import bulletproof ingestion system
try:
    from ingest.intake_router import IntakeRouter
    BULLETPROOF_INGESTION_AVAILABLE = True
    logger = logging.getLogger(__name__)
    logger.info("‚úÖ Bulletproof ingestion system available")
except ImportError as e:
    BULLETPROOF_INGESTION_AVAILABLE = False
    logger = logging.getLogger(__name__)
    logger.warning(f"‚ö†Ô∏è Bulletproof ingestion system not available: {e}")

# Configure logging
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

app = FastAPI(title="Owlin API", version="1.0.0")

# Configure CORS
app.add_middleware(
    CORSMiddleware,
    allow_origins=["*"],
    allow_credentials=True,
    allow_methods=["*"],
    allow_headers=["*"],
)

# Include analytics routes
app.include_router(analytics_router, prefix="/api")

# Include document queue routes
app.include_router(document_queue_router, prefix="/api")

# Create upload directory
upload_dir = Path("data/uploads")
upload_dir.mkdir(parents=True, exist_ok=True)

# Initialize bulletproof ingestion router if available
intake_router = None
if BULLETPROOF_INGESTION_AVAILABLE:
    try:
        intake_router = IntakeRouter()
        logger.info("‚úÖ Bulletproof ingestion router initialized")
    except Exception as e:
        logger.error(f"‚ùå Failed to initialize bulletproof ingestion router: {e}")
        BULLETPROOF_INGESTION_AVAILABLE = False

@app.get("/")
async def root():
    return {"message": "Owlin API is running"}

@app.get("/health")
async def health_check():
    return {"status": "ok", "bulletproof_ingestion": BULLETPROOF_INGESTION_AVAILABLE}

@app.get("/api/health")
def api_health_check():
    return {"status": "ok", "bulletproof_ingestion": BULLETPROOF_INGESTION_AVAILABLE}

# Real OCR processing function
async def process_file_with_real_ocr(file_path: Path, original_filename: str) -> Dict[str, Any]:
    """Process file with real OCR and extract invoice data"""
    try:
        logger.info(f"üîç Starting real OCR processing for: {file_path}")
        
        # Import unified OCR engine
        try:
            from ocr.unified_ocr_engine import get_unified_ocr_engine
            from db_manager import save_invoice_to_db, save_uploaded_file_to_db
        except ImportError as import_error:
            logger.error(f"‚ùå Failed to import unified OCR modules: {import_error}")
            # Fallback to basic text processing
            return await process_file_with_basic_ocr(file_path, original_filename)
        
        # Process the file with unified engine
        logger.info(f"üìÑ Processing document with unified OCR: {file_path}")
        try:
            unified_engine = get_unified_ocr_engine()
            result = unified_engine.process_document(str(file_path))
            
            if result.success:
                logger.info(f"‚úÖ OCR completed: {result.engine_used}, confidence: {result.overall_confidence:.2f}")
                
                # Use unified result data
                all_text = result.raw_text
                word_count = result.word_count
                avg_confidence = result.overall_confidence
                line_items = result.line_items
                document_type = result.document_type
                
                # Ensure confidence is properly normalized (0-100 for UI)
                if avg_confidence <= 1.0:
                    ui_confidence = max(30.0, min(95.0, avg_confidence * 100.0))  # Minimum 30%, max 95%
                else:
                    ui_confidence = max(30.0, min(95.0, avg_confidence))  # Already in 0-100 range
                
                # Create extracted_data dict for compatibility
                extracted_data = {
                    "supplier_name": result.supplier,
                    "invoice_number": result.invoice_number,
                    "invoice_date": result.date,
                    "total_amount": result.total_amount
                }
                
                logger.info(f"üìä Unified OCR completed: {word_count} words, {ui_confidence:.2f} confidence, engine: {result.engine_used}")
                
            else:
                logger.error(f"‚ùå Unified OCR failed: {result.error_message}")
                # Fallback to basic text processing
                return await process_file_with_basic_ocr(file_path, original_filename)
                
        except Exception as e:
            logger.error(f"‚ùå Unified OCR import/processing failed: {e}")
            # Fallback to basic text processing
            return await process_file_with_basic_ocr(file_path, original_filename)
        
        # Save to database
        file_id = str(uuid.uuid4())
        try:
            # Save uploaded file record
            save_uploaded_file_to_db(
                file_id=file_id,
                original_filename=original_filename,
                file_path=str(file_path),
                file_type=document_type,
                confidence=avg_confidence
            )
            
            # Save invoice data if it's an invoice
            if document_type == "invoice":
                logger.info(f"üíæ Attempting to save invoice to database: {file_id}")
                logger.info(f"üíæ Document type: {document_type}")
                logger.info(f"üíæ Supplier: {extracted_data['supplier_name']}")
                logger.info(f"üíæ Invoice number: {extracted_data['invoice_number']}")
                try:
                    # Check if this was LLM processing
                    field_confidence = None
                    raw_extraction = None
                    warnings = None
                    
                    if result.engine_used.startswith('llm-'):
                        # Extract LLM-specific data from line items
                        field_confidence = {}
                        if line_items:
                            # Calculate confidence from line items
                            for item in line_items:
                                if isinstance(item, dict) and 'confidence' in item:
                                    field_confidence[item.get('description', 'line_item')] = item['confidence']
                        
                        raw_extraction = {
                            'engine': result.engine_used,
                            'line_items_count': len(line_items),
                            'processing_time': result.processing_time
                        }
                        
                        warnings = []
                    
                    result_save = save_invoice_to_db(
                        invoice_id=file_id,
                        supplier_name=extracted_data["supplier_name"],
                        invoice_number=extracted_data["invoice_number"],
                        invoice_date=extracted_data["invoice_date"],
                        total_amount=extracted_data["total_amount"],
                        confidence=avg_confidence,
                        ocr_text=all_text,
                        line_items=line_items,
                        field_confidence=field_confidence,
                        raw_extraction=raw_extraction,
                        warnings=warnings
                    )
                    logger.info(f"‚úÖ Invoice save result: {result_save}")
                except Exception as db_error:
                    logger.error(f"‚ùå Database save failed: {db_error}")
                    import traceback
                    logger.error(f"‚ùå Database save traceback: {traceback.format_exc()}")
            else:
                logger.info(f"üìÑ Document type is '{document_type}', not saving to invoices table")
        except Exception as db_error:
            logger.error(f"‚ùå Database save failed: {db_error}")
        
        return {
            "confidence": ui_confidence,
            "supplier_name": extracted_data["supplier_name"],
            "invoice_number": extracted_data["invoice_number"],
            "total_amount": extracted_data["total_amount"],
            "invoice_date": extracted_data["invoice_date"],
            "raw_text": all_text[:1000] + "..." if len(all_text) > 1000 else all_text,
            "word_count": word_count,
            "line_items": [item.__dict__ if hasattr(item, '__dict__') else item for item in line_items[:10]],  # Limit to first 10 items
            "document_type": document_type,
            "file_id": file_id,
            "engine_used": result.engine_used
        }
        
    except Exception as e:
        logger.error(f"‚ùå Real OCR processing failed: {e}")
        # Final fallback to basic processing
        return await process_file_with_basic_ocr(file_path, original_filename)

async def process_file_with_basic_ocr(file_path: Path, original_filename: str) -> Dict[str, Any]:
    """Basic OCR processing as fallback"""
    try:
        logger.info(f"üîÑ Using basic OCR processing for: {file_path}")
        
        file_extension = file_path.suffix.lower()
        
        # Handle text files
        if file_extension in {'.txt', '.md'}:
            logger.info("üìù Processing as text file")
            with open(file_path, 'r', encoding='utf-8') as f:
                text_content = f.read()
            
            extracted_data = extract_invoice_data_from_text(text_content)
            document_type = classify_document_type(text_content)
            
            logger.info(f"üìÑ Basic OCR - Document type: {document_type}")
            logger.info(f"üìÑ Basic OCR - Supplier: {extracted_data['supplier_name']}")
            
            return {
                "confidence": 85.0,  # High confidence for text files (0-100 scale)
                "supplier_name": extracted_data["supplier_name"],
                "invoice_number": extracted_data["invoice_number"],
                "total_amount": extracted_data["total_amount"],
                "invoice_date": extracted_data["invoice_date"],
                "raw_text": text_content[:1000] + "..." if len(text_content) > 1000 else text_content,
                "word_count": len(text_content.split()),
                "line_items": [],
                "document_type": document_type,
                "file_id": str(uuid.uuid4())
            }
        
        # Handle image files with basic Tesseract
        elif file_extension in {'.jpg', '.jpeg', '.png', '.tiff', '.tif'}:
            try:
                import pytesseract
                from PIL import Image
                
                image = Image.open(file_path)
                text_content = pytesseract.image_to_string(image)
                
                if text_content.strip():
                    extracted_data = extract_invoice_data_from_text(text_content)
                    document_type = classify_document_type(text_content)
                    
                    return {
                        "confidence": 75.0,  # Medium confidence for image OCR (0-100 scale)
                        "supplier_name": extracted_data["supplier_name"],
                        "invoice_number": extracted_data["invoice_number"],
                        "total_amount": extracted_data["total_amount"],
                        "invoice_date": extracted_data["invoice_date"],
                        "raw_text": text_content[:1000] + "..." if len(text_content) > 1000 else text_content,
                        "word_count": len(text_content.split()),
                        "line_items": [],
                        "document_type": document_type,
                        "file_id": str(uuid.uuid4())
                    }
                else:
                    # No text extracted from image
                    return {
                        "confidence": 30.0,  # Low confidence for no text extracted (0-100 scale)
                        "supplier_name": "No text extracted",
                        "invoice_number": "Unknown",
                        "total_amount": 0.0,
                        "invoice_date": datetime.now().strftime("%Y-%m-%d"),
                        "raw_text": "No text could be extracted from this image",
                        "word_count": 0,
                        "line_items": [],
                        "document_type": "unknown",
                        "file_id": str(uuid.uuid4())
                    }
                    
            except Exception as img_error:
                logger.error(f"‚ùå Basic image OCR failed: {img_error}")
                return {
                    "confidence": 30.0,  # Low confidence for processing failure (0-100 scale)
                    "supplier_name": "Image processing failed",
                    "invoice_number": "Unknown",
                    "total_amount": 0.0,
                    "invoice_date": datetime.now().strftime("%Y-%m-%d"),
                    "raw_text": f"Image processing error: {str(img_error)}",
                    "word_count": 0,
                    "line_items": [],
                    "document_type": "unknown",
                    "file_id": str(uuid.uuid4())
                }
        
        # Handle PDF files
        elif file_extension == '.pdf':
            try:
                import fitz  # PyMuPDF
                
                doc = fitz.open(file_path)
                text_content = ""
                
                # Extract text from all pages
                for page_num in range(len(doc)):
                    page = doc.load_page(page_num)
                    text_content += page.get_text()
                
                doc.close()
                
                if text_content.strip():
                    logger.info(f"üìÑ PDF text extraction successful: {len(text_content)} characters")
                    
                    # Check for multiple invoices
                    invoice_indicators = text_content.lower().count('invoice')
                    if invoice_indicators > 1:
                        logger.info(f"üìÑ Multiple invoices detected: {invoice_indicators} invoice indicators")
                        # For now, process as single invoice but flag for future multi-invoice handling
                        extracted_data = extract_invoice_data_from_text(text_content)
                        document_type = classify_document_type(text_content)
                        
                        # Calculate confidence based on data extraction success
                        word_count = len(text_content.split())
                        base_confidence = min(0.95, max(0.3, word_count / 50))
                        
                        # Boost confidence if key data was extracted
                        confidence_boost = 0.0
                        if extracted_data["supplier_name"] != "Unknown Supplier":
                            confidence_boost += 0.2
                        if extracted_data["invoice_number"] != "Unknown":
                            confidence_boost += 0.2
                        if extracted_data["total_amount"] > 0:
                            confidence_boost += 0.2
                        if extracted_data["invoice_date"] != datetime.now().strftime("%Y-%m-%d"):
                            confidence_boost += 0.1
                        
                        final_confidence = min(0.95, base_confidence + confidence_boost)
                        
                        return {
                            "confidence": final_confidence,
                            "supplier_name": extracted_data["supplier_name"],
                            "invoice_number": extracted_data["invoice_number"],
                            "total_amount": extracted_data["total_amount"],
                            "invoice_date": extracted_data["invoice_date"],
                            "raw_text": text_content[:1000] + "..." if len(text_content) > 1000 else text_content,
                            "word_count": word_count,
                            "line_items": [],
                            "document_type": document_type,
                            "file_id": str(uuid.uuid4()),
                            "multi_invoice": True,
                            "invoice_count": invoice_indicators
                        }
                    else:
                        # Single invoice processing
                        extracted_data = extract_invoice_data_from_text(text_content)
                        document_type = classify_document_type(text_content)
                        
                        # Extract line items
                        line_items = []
                        try:
                            # Enhanced line item extraction from text
                            lines = text_content.split('\n')
                            for line in lines:
                                # Look for specific patterns like "2 BUCK-EK30 Buckskin - 30L E-keg ¬£98.50"
                                if re.search(r'(\d+)\s+([A-Z0-9\-]+)\s+(.*?)\s+[¬£$‚Ç¨](\d+\.?\d*)', line, re.IGNORECASE):
                                    match = re.search(r'(\d+)\s+([A-Z0-9\-]+)\s+(.*?)\s+[¬£$‚Ç¨](\d+\.?\d*)', line, re.IGNORECASE)
                                    if match:
                                        try:
                                            qty = int(match.group(1))
                                            code = match.group(2)
                                            description = match.group(3).strip()
                                            unit_price = float(match.group(4))
                                            
                                            line_items.append({
                                                "quantity": qty,
                                                "code": code,
                                                "description": description,
                                                "unit_price": unit_price,
                                                "total_price": qty * unit_price
                                            })
                                        except:
                                            continue
                                
                                # Also look for simpler patterns like "2 BUCK-EK30 ¬£98.50"
                                elif re.search(r'(\d+)\s+([A-Z0-9\-]+)\s+[¬£$‚Ç¨](\d+\.?\d*)', line, re.IGNORECASE):
                                    match = re.search(r'(\d+)\s+([A-Z0-9\-]+)\s+[¬£$‚Ç¨](\d+\.?\d*)', line, re.IGNORECASE)
                                    if match:
                                        try:
                                            qty = int(match.group(1))
                                            code = match.group(2)
                                            unit_price = float(match.group(3))
                                            
                                            line_items.append({
                                                "quantity": qty,
                                                "code": code,
                                                "description": f"Item {code}",
                                                "unit_price": unit_price,
                                                "total_price": qty * unit_price
                                            })
                                        except:
                                            continue
                                
                                # Look for patterns like "QTY CODE ITEM UNIT PRICE" or "2 BUCK-EK30 Buckskin - 30L E-keg ¬£98.50"
                                elif re.search(r'\d+\s+[A-Z]+\s+[A-Z\s\-]+\s+[¬£$‚Ç¨]?\d+', line, re.IGNORECASE):
                                    parts = line.split()
                                    if len(parts) >= 4:
                                        try:
                                            qty = int(parts[0])
                                            code = parts[1]
                                            # Look for price at end of line
                                            price_match = re.search(r'[¬£$‚Ç¨]?(\d+\.?\d*)', line)
                                            if price_match:
                                                unit_price = float(price_match.group(1))
                                                # Extract description between code and price
                                                price_start = line.find(price_match.group(0))
                                                description = line[len(parts[0]) + len(parts[1]) + 2:price_start].strip()
                                                
                                                line_items.append({
                                                    "quantity": qty,
                                                    "code": code,
                                                    "description": description,
                                                    "unit_price": unit_price,
                                                    "total_price": qty * unit_price
                                                })
                                        except:
                                            continue
                        except Exception as line_error:
                            logger.error(f"‚ùå Line item extraction failed: {line_error}")
                        
                        # Calculate confidence based on data extraction success
                        word_count = len(text_content.split())
                        base_confidence = max(0.3, min(0.95, word_count / 30))  # Minimum 30%, more generous calculation
                        
                        # Boost confidence if key data was extracted
                        confidence_boost = 0.0
                        if extracted_data["supplier_name"] != "Unknown Supplier":
                            confidence_boost += 0.3
                        if extracted_data["invoice_number"] != "Unknown":
                            confidence_boost += 0.2
                        if extracted_data["total_amount"] > 0:
                            confidence_boost += 0.2
                        if extracted_data["invoice_date"] != datetime.now().strftime("%Y-%m-%d"):
                            confidence_boost += 0.1
                        if line_items:
                            confidence_boost += 0.2  # Bonus for line items
                        
                        final_confidence = min(0.95, base_confidence + confidence_boost)
                        # Ensure minimum confidence of 30%
                        final_confidence = max(0.3, final_confidence)
                        
                        # If we have good data but low confidence, boost it
                        if (extracted_data["supplier_name"] != "Unknown Supplier" and 
                            extracted_data["total_amount"] > 0 and 
                            final_confidence < 0.5):
                            final_confidence = 0.7  # Boost to reasonable confidence
                        
                        return {
                            "confidence": final_confidence,
                            "supplier_name": extracted_data["supplier_name"],
                            "invoice_number": extracted_data["invoice_number"],
                            "total_amount": extracted_data["total_amount"],
                            "invoice_date": extracted_data["invoice_date"],
                            "raw_text": text_content[:1000] + "..." if len(text_content) > 1000 else text_content,
                            "word_count": word_count,
                            "line_items": line_items,
                            "document_type": document_type,
                            "file_id": str(uuid.uuid4())
                        }
                else:
                    # Try OCR on PDF pages if text extraction fails
                    logger.info("üìÑ No text extracted from PDF, trying OCR on pages")
                    try:
                        from pdf2image import convert_from_path
                        images = convert_from_path(file_path)
                        
                        ocr_text = ""
                        for i, image in enumerate(images):
                            try:
                                import pytesseract
                                page_text = pytesseract.image_to_string(image)
                                ocr_text += f"Page {i+1}:\n{page_text}\n"
                            except Exception as ocr_error:
                                logger.error(f"‚ùå OCR failed on page {i+1}: {ocr_error}")
                        
                        if ocr_text.strip():
                            extracted_data = extract_invoice_data_from_text(ocr_text)
                            document_type = classify_document_type(ocr_text)
                            
                            return {
                                "confidence": 0.6,  # Medium confidence for OCR on PDF
                                "supplier_name": extracted_data["supplier_name"],
                                "invoice_number": extracted_data["invoice_number"],
                                "total_amount": extracted_data["total_amount"],
                                "invoice_date": extracted_data["invoice_date"],
                                "raw_text": ocr_text[:1000] + "..." if len(ocr_text) > 1000 else ocr_text,
                                "word_count": len(ocr_text.split()),
                                "line_items": [],
                                "document_type": document_type,
                                "file_id": str(uuid.uuid4())
                            }
                        else:
                            return {
                                "confidence": 0.3,
                                "supplier_name": "No text extracted from PDF",
                                "invoice_number": "Unknown",
                                "total_amount": 0.0,
                                "invoice_date": datetime.now().strftime("%Y-%m-%d"),
                                "raw_text": "No text could be extracted from this PDF",
                                "word_count": 0,
                                "line_items": [],
                                "document_type": "unknown",
                                "file_id": str(uuid.uuid4())
                            }
                    except Exception as pdf_ocr_error:
                        logger.error(f"‚ùå PDF OCR failed: {pdf_ocr_error}")
                        return {
                            "confidence": 0.3,
                            "supplier_name": "PDF processing failed",
                            "invoice_number": "Unknown",
                            "total_amount": 0.0,
                            "invoice_date": datetime.now().strftime("%Y-%m-%d"),
                            "raw_text": f"PDF processing error: {str(pdf_ocr_error)}",
                            "word_count": 0,
                            "line_items": [],
                            "document_type": "unknown",
                            "file_id": str(uuid.uuid4())
                        }
                    
            except Exception as pdf_error:
                logger.error(f"‚ùå Basic PDF processing failed: {pdf_error}")
                return {
                    "confidence": 0.3,
                    "supplier_name": "PDF processing failed",
                    "invoice_number": "Unknown",
                    "total_amount": 0.0,
                    "invoice_date": datetime.now().strftime("%Y-%m-%d"),
                    "raw_text": f"PDF processing error: {str(pdf_error)}",
                    "word_count": 0,
                    "line_items": [],
                    "document_type": "unknown",
                    "file_id": str(uuid.uuid4())
                }
        
        # Unknown file type
        else:
            return {
                "confidence": 0.3,
                "supplier_name": "Unsupported file type",
                "invoice_number": "Unknown",
                "total_amount": 0.0,
                "invoice_date": datetime.now().strftime("%Y-%m-%d"),
                "raw_text": f"Unsupported file type: {file_extension}",
                "word_count": 0,
                "line_items": [],
                "document_type": "unknown",
                "file_id": str(uuid.uuid4())
            }
            
    except Exception as e:
        logger.error(f"‚ùå Basic OCR processing failed: {e}")
        return {
            "confidence": 0.3,
            "supplier_name": "Processing failed",
            "invoice_number": "Unknown",
            "total_amount": 0.0,
            "invoice_date": datetime.now().strftime("%Y-%m-%d"),
            "raw_text": f"Processing error: {str(e)}",
            "word_count": 0,
            "line_items": [],
            "document_type": "unknown",
            "file_id": str(uuid.uuid4())
        }

def extract_invoice_data_from_text(text: str) -> Dict[str, Any]:
    """Extract basic invoice data from OCR text"""
    text_lower = text.lower()
    
    # Extract supplier name - look for the actual supplier (not bill-to)
    supplier_name = "Unknown Supplier"
    
    # Pattern 1: Look for company name in header/logo area (usually at top)
    lines = text.split('\n')
    for i, line in enumerate(lines[:15]):  # Check first 15 lines
        line_upper = line.upper()
        # Look for brewing companies, suppliers in header
        if any(keyword in line_upper for keyword in ['BREWING', 'BREWERY', 'WILD HORSE', 'SUPPLIER', 'CO LTD', 'COMPANY']):
            supplier_name = line.strip()
            break
        # Skip table headers and common invoice words
        elif any(keyword in line_upper for keyword in ['QTY', 'CODE', 'ITEM', 'UNIT', 'PRICE', 'TOTAL', 'VAT', 'DISCOUNT', 'INVOICE 1', 'INVOICE 2', 'INVOICE #']):
            continue
        # Skip empty lines and common invoice labels
        elif line.strip() and not any(keyword in line_upper for keyword in ['BILL TO:', 'DELIVER TO:', 'DATE:', 'TOTAL:', 'DUE BY:', 'ISSUE DATE:']):
            # This might be the supplier name if it looks like a company
            if len(line.strip()) > 3 and not line.strip().isdigit() and not line.strip().startswith('Invoice'):
                # Additional check: make sure it's not a line item code
                if not re.match(r'^[A-Z0-9\-]+$', line.strip()) and len(line.strip()) > 10:
                    supplier_name = line.strip()
                    break
    
    # Pattern 2: Look for "Invoice from:" or "Supplier:" patterns
    if supplier_name == "Unknown Supplier":
        supplier_match = re.search(r'(?:invoice\s+from|supplier|from):\s*([^\n]+)', text, re.IGNORECASE)
        if supplier_match:
            supplier_name = supplier_match.group(1).strip()
    
    # Pattern 3: Look for company name patterns in the text
    if supplier_name == "Unknown Supplier":
        company_patterns = [
            r'([A-Z][A-Z\s&]+(?:BREWING|BREWERY|CO|COMPANY|LTD|LIMITED|INC|CORP|LLC))',
            r'([A-Z][A-Z\s&]+(?:CO\.|COMPANY|LTD\.|LIMITED))',
            r'([A-Z][A-Z\s&]+(?:BREWING|BREWERY))',
            r'(WILD\s+HORSE\s+[A-Z\s]+)',  # Specific to your invoice
        ]
        
        for pattern in company_patterns:
            match = re.search(pattern, text)
            if match:
                supplier_name = match.group(1).strip()
                break
    
    # Pattern 4: Look for company name in the first few lines (before "Bill to:")
    if supplier_name == "Unknown Supplier":
        lines = text.split('\n')
        for line in lines[:8]:  # Check first 8 lines
            if line.strip() and not any(keyword in line.lower() for keyword in ['bill to:', 'invoice #', 'date:', 'total:', 'qty', 'code', 'item', 'unit', 'price', 'issue date:']):
                # This might be the supplier name
                supplier_name = line.strip()
                break
    
    # Extract invoice number - look for multiple patterns
    invoice_number = "Unknown"
    
    # Pattern 1: Look for "Invoice #" or "Invoice Number"
    invoice_match = re.search(r'invoice\s*#?\s*:?\s*([^\n\s]+)', text, re.IGNORECASE)
    if invoice_match:
        invoice_number = invoice_match.group(1).strip()
        # Clean up if it contains other text
        if "supplier" in invoice_number.lower() or "bill" in invoice_number.lower():
            # Try alternative pattern
            alt_match = re.search(r'#\s*(\d+)', text, re.IGNORECASE)
            if alt_match:
                invoice_number = alt_match.group(1)
    else:
        # Pattern 2: Look for invoice number patterns
        number_patterns = [
            r'#\s*(\d+)',
            r'invoice\s*(\d+)',
            r'(\d{5,})',  # Look for 5+ digit numbers
        ]
        
        for pattern in number_patterns:
            match = re.search(pattern, text, re.IGNORECASE)
            if match:
                invoice_number = match.group(1)
                break
    
    # Extract total amount - look for multiple patterns
    total_amount = 0.0
    
    # Pattern 1: Look for "Total (inc. VAT):" or "Total including VAT" - PRIORITY
    vat_total_match = re.search(r'total\s*(?:inc\.?\s*vat|including\s*vat)\s*:?\s*[¬£$‚Ç¨]?([\d,]+\.?\d*)', text, re.IGNORECASE)
    if vat_total_match:
        try:
            total_amount = float(vat_total_match.group(1).replace(',', ''))
        except:
            pass
    
    # Pattern 2: Look for "Total:" or "Total Due:" (usually includes VAT)
    if total_amount == 0.0:
        total_match = re.search(r'total\s*(?:due)?\s*:?\s*[¬£$‚Ç¨]?([\d,]+\.?\d*)', text, re.IGNORECASE)
        if total_match:
            try:
                total_amount = float(total_match.group(1).replace(',', ''))
            except:
                pass
    
    # Pattern 3: Look for "Total:" followed by amount (usually includes VAT)
    if total_amount == 0.0:
        simple_total_match = re.search(r'total\s*:?\s*[¬£$‚Ç¨]?([\d,]+\.?\d*)', text, re.IGNORECASE)
        if simple_total_match:
            try:
                total_amount = float(simple_total_match.group(1).replace(',', ''))
            except:
                pass
    
    # Pattern 4: Look for currency amounts at the end (largest amount, but not invoice numbers)
    if total_amount == 0.0:
        amount_matches = re.findall(r'[¬£$‚Ç¨]?\s*([\d,]+\.?\d*)', text)
        amounts = []
        for amt in amount_matches:
            try:
                clean_amt = amt.replace(',', '')
                if clean_amt.replace('.', '').isdigit():
                    amount = float(clean_amt)
                    # Filter out years, small amounts, invoice numbers, and look for larger amounts
                    if amount > 100 and amount < 100000 and amount != 73318:  # Exclude invoice number
                        amounts.append(amount)
            except:
                continue
        if amounts:
            total_amount = max(amounts)  # Take the largest amount as total
    
    # Pattern 5: Look for amounts in the last few lines (where totals usually are)
    if total_amount == 0.0:
        lines = text.split('\n')
        for line in reversed(lines[-10:]):  # Check last 10 lines
            amount_match = re.search(r'[¬£$‚Ç¨]?\s*([\d,]+\.?\d*)', line)
            if amount_match:
                try:
                    amount = float(amount_match.group(1).replace(',', ''))
                    if amount > 100 and amount < 100000 and amount != 73318:  # Exclude invoice number
                        total_amount = amount
                        break
                except:
                    continue
    
    # Pattern 6: Look specifically for "Total (inc. VAT): ¬£556.20" pattern
    if total_amount == 0.0 or total_amount == 2025.0:  # Reset if we got the wrong amount
        vat_total_match = re.search(r'total\s*\(inc\.?\s*vat\)\s*:?\s*[¬£$‚Ç¨]?([\d,]+\.?\d*)', text, re.IGNORECASE)
        if vat_total_match:
            try:
                total_amount = float(vat_total_match.group(1).replace(',', ''))
            except:
                pass
    
    # Pattern 7: Look for the largest amount that's not an invoice number or date
    if total_amount == 0.0 or total_amount == 2025.0:
        amount_matches = re.findall(r'[¬£$‚Ç¨]?\s*([\d,]+\.?\d*)', text)
        amounts = []
        for amt in amount_matches:
            try:
                clean_amt = amt.replace(',', '')
                if clean_amt.replace('.', '').isdigit():
                    amount = float(clean_amt)
                    # Filter out years, small amounts, invoice numbers, and look for larger amounts
                    if amount > 50 and amount < 100000 and amount != 73318 and amount != 2025:
                        amounts.append(amount)
            except:
                continue
        if amounts:
            # Take the largest amount that looks like a total
            amounts.sort(reverse=True)
            for amount in amounts:
                if amount > 100:  # Prefer larger amounts as totals
                    total_amount = amount
                    break
    
    # Extract invoice date - look for multiple patterns
    invoice_date = datetime.now().strftime("%Y-%m-%d")
    date_match = re.search(r'(?:issue\s+date|invoice\s+date|date):\s*([^\n]+)', text, re.IGNORECASE)
    if date_match:
        date_str = date_match.group(1).strip()
        try:
            if ',' in date_str and any(day in date_str.lower() for day in ['monday', 'tuesday', 'wednesday', 'thursday', 'friday', 'saturday', 'sunday']):
                parsed_date = datetime.strptime(date_str, "%A, %d %B %Y")
                invoice_date = parsed_date.strftime("%Y-%m-%d")
            elif '/' in date_str:
                parsed_date = datetime.strptime(date_str, "%d/%m/%Y")
                invoice_date = parsed_date.strftime("%Y-%m-%d")
        except:
            pass
    
    if invoice_date == datetime.now().strftime("%Y-%m-%d"):
        date_patterns = [
            r'(\d{1,2}[/-]\d{1,2}[/-]\d{2,4})',
            r'(\d{1,2}\s+(?:Jan|Feb|Mar|Apr|May|Jun|Jul|Aug|Sep|Oct|Nov|Dec)\s+\d{4})',
        ]
        for pattern in date_patterns:
            match = re.search(pattern, text, re.IGNORECASE)
            if match:
                try:
                    date_str = match.group(1)
                    if '/' in date_str:
                        parts = date_str.split('/')
                        if len(parts[2]) == 2:
                            date_str = f"{parts[0]}/{parts[1]}/20{parts[2]}"
                        parsed_date = datetime.strptime(date_str, "%d/%m/%Y")
                    elif '-' in date_str:
                        parts = date_str.split('-')
                        if len(parts[2]) == 2:
                            date_str = f"{parts[0]}-{parts[1]}-20{parts[2]}"
                        parsed_date = datetime.strptime(date_str, "%d-%m-%Y")
                    else:
                        parsed_date = datetime.strptime(date_str, "%d %b %Y")
                    invoice_date = parsed_date.strftime("%Y-%m-%d")
                    break
                except:
                    pass
    
    # Additional check: look for "Friday, 4 July 2025" pattern specifically
    if invoice_date == datetime.now().strftime("%Y-%m-%d"):
        specific_date_match = re.search(r'(?:Friday|Monday|Tuesday|Wednesday|Thursday|Saturday|Sunday),\s*(\d{1,2})\s+(?:January|February|March|April|May|June|July|August|September|October|November|December)\s+(\d{4})', text, re.IGNORECASE)
        if specific_date_match:
            try:
                day = int(specific_date_match.group(1))
                year = int(specific_date_match.group(2))
                month_str = specific_date_match.group(0).split()[2]  # Get month name
                month_map = {
                    'january': 1, 'february': 2, 'march': 3, 'april': 4,
                    'may': 5, 'june': 6, 'july': 7, 'august': 8,
                    'september': 9, 'october': 10, 'november': 11, 'december': 12
                }
                month = month_map.get(month_str.lower())
                if month:
                    parsed_date = datetime(year, month, day)
                    invoice_date = parsed_date.strftime("%Y-%m-%d")
            except:
                pass
    
    return {
        "supplier_name": supplier_name,
        "invoice_number": invoice_number,
        "total_amount": total_amount,
        "invoice_date": invoice_date
    }

def classify_document_type(text: str) -> str:
    """Classify document type based on content"""
    text_lower = text.lower()
    
    # Check for delivery note indicators
    delivery_indicators = ['delivery note', 'delivery receipt', 'goods received', 'delivery']
    if any(indicator in text_lower for indicator in delivery_indicators):
        return "delivery_note"
    
    # Check for utility bill indicators
    utility_indicators = ['utility', 'electricity', 'gas', 'water', 'phone', 'internet', 'council tax']
    if any(indicator in text_lower for indicator in utility_indicators):
        return "utility"
    
    # Check for invoice indicators
    invoice_indicators = ['invoice', 'bill', 'statement', 'account']
    if any(indicator in text_lower for indicator in invoice_indicators):
        return "invoice"
    
    # Default to invoice if no clear classification
    return "invoice"

# Import the new unified multi-invoice detection system
try:
    from ocr.multi_invoice_detector import get_multi_invoice_detector, DetectionConfig, DetectionResult
    UNIFIED_DETECTION_AVAILABLE = True
    logger.info("‚úÖ Unified multi-invoice detection system loaded successfully")
except ImportError as e:
    logger.warning(f"‚ö†Ô∏è Unified multi-invoice detection not available: {e}")
    UNIFIED_DETECTION_AVAILABLE = False

# Legacy function for backward compatibility (will be deprecated)
def is_actual_multi_invoice(text: str) -> bool:
    """
    Improved multi-invoice detection that's more conservative.
    Only detects multi-invoice when there are clearly multiple distinct invoices.
    """
    text_lower = text.lower()
    
    # Count unique invoice numbers
    invoice_patterns = [
        r'invoice\s*#?\s*:?\s*([^\n\s]+)',
        r'#\s*(\d+)',
        r'invoice\s*(\d+)',
    ]
    
    unique_invoices = set()
    for pattern in invoice_patterns:
        matches = re.findall(pattern, text_lower)
        for match in matches:
            if match.strip() and len(match.strip()) >= 3:
                unique_invoices.add(match.strip())
    
    # Count unique suppliers
    supplier_patterns = [
        r'([A-Z][A-Z\s&]+(?:BREWING|BREWERY|CO|COMPANY|LTD|LIMITED|INC|CORP|LLC))',
        r'([A-Z][A-Z\s&]+(?:CO\.|COMPANY|LTD\.|LIMITED))',
        r'([A-Z][A-Z\s&]+(?:BREWING|BREWERY))',
    ]
    
    unique_suppliers = set()
    for pattern in supplier_patterns:
        matches = re.findall(pattern, text)
        for match in matches:
            if match.strip() and len(match.strip()) > 5:
                unique_suppliers.add(match.strip())
    
    # Count page separators
    page_markers = re.findall(r'(?:page|p\.?)\s*\d+', text_lower)
    
    # More conservative detection criteria
    has_multiple_invoices = len(unique_invoices) > 1
    has_page_separators = len(page_markers) > 1  # Require more than 1 page marker
    has_multiple_suppliers = len(unique_suppliers) > 1
    
    # Additional validation: require stronger evidence
    if has_multiple_invoices:
        # Make sure the invoice numbers are actually different (not just variations)
        invoice_numbers = list(unique_invoices)
        for i, inv1 in enumerate(invoice_numbers):
            for inv2 in invoice_numbers[i+1:]:
                # Check if they're similar (might be variations of the same number)
                if inv1.lower() in inv2.lower() or inv2.lower() in inv1.lower():
                    has_multiple_invoices = False
                    break
    
    # Only return True if we have strong evidence of multiple invoices
    # Require at least 2 of the 3 conditions to be true
    conditions_met = sum([has_multiple_invoices, has_page_separators, has_multiple_suppliers])
    
    return conditions_met >= 2

# Upload endpoint that frontend expects
@app.post("/api/upload")
async def upload_file(file: UploadFile = File(...)):
    try:
        # Validate file
        if not file.filename:
            raise HTTPException(status_code=400, detail="No file provided")
        
        # Check file type
        allowed_extensions = {'.pdf', '.jpg', '.jpeg', '.png', '.tiff', '.tif', '.txt', '.md'}
        file_extension = Path(file.filename).suffix.lower()
        if file_extension not in allowed_extensions:
            raise HTTPException(status_code=400, detail="File type not supported. Please upload PDF, JPG, JPEG, PNG, TIFF, TXT, or MD files.")
        
        # Generate unique filename
        file_id = str(uuid.uuid4())
        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
        extension = Path(file.filename).suffix
        filename = f"{file_id}_{timestamp}{extension}"
        file_path = upload_dir / filename
        
        # Save file
        with open(file_path, "wb") as buffer:
            content = await file.read()
            buffer.write(content)
        
        logger.info(f"üìÅ File saved: {file_path}")
        
        # Process file with REAL OCR
        try:
            ocr_data = await process_file_with_real_ocr(file_path, file.filename)
        except Exception as ocr_error:
            logger.error(f"‚ùå OCR processing failed: {ocr_error}")
            # Fallback to text processing for non-image files
            if file_extension in {'.txt', '.md'}:
                logger.info("üìù Processing as text file")
                with open(file_path, 'r', encoding='utf-8') as f:
                    text_content = f.read()
                extracted_data = extract_invoice_data_from_text(text_content)
                ocr_data = {
                    "confidence": 85,
                    "supplier_name": extracted_data["supplier_name"],
                    "invoice_number": extracted_data["invoice_number"],
                    "total_amount": extracted_data["total_amount"],
                    "invoice_date": extracted_data["invoice_date"],
                    "raw_text": text_content[:1000] + "..." if len(text_content) > 1000 else text_content,
                    "word_count": len(text_content.split()),
                    "line_items": [],
                    "document_type": classify_document_type(text_content),
                    "file_id": file_id
                }
            else:
                # For image files that fail OCR, return error
                raise HTTPException(status_code=500, detail=f"OCR processing failed: {str(ocr_error)}")
        
        # Check for multi-invoice content using unified detection system
        multi_invoice_detected = False
        detection_result = None
        
        if file_extension in {'.pdf', '.txt', '.md'}:
            try:
                # Get the raw text for analysis
                raw_text = ocr_data.get("raw_text", "")
                logger.info(f"üîç Analyzing text for multi-invoice detection (length: {len(raw_text)} chars)")
                
                if UNIFIED_DETECTION_AVAILABLE:
                    # Use the new unified multi-invoice detection system
                    logger.info("üîÑ Using unified multi-invoice detection system")
                    detector = get_multi_invoice_detector()
                    detection_result = detector.detect(raw_text)
                    multi_invoice_detected = detection_result.is_multi_invoice
                    
                    logger.info(f"üîç Unified detection result: multi_invoice={multi_invoice_detected}, confidence={detection_result.confidence:.2f}")
                    logger.info(f"üîç Detected invoices: {len(detection_result.detected_invoices)}")
                    logger.info(f"üîç Page separations: {len(detection_result.page_separations)}")
                    logger.info(f"üîç Supplier variations: {len(detection_result.supplier_variations)}")
                    
                    if detection_result.warnings:
                        logger.warning(f"‚ö†Ô∏è Detection warnings: {detection_result.warnings}")
                    
                    if detection_result.error_messages:
                        logger.error(f"‚ùå Detection errors: {detection_result.error_messages}")
                else:
                    # Fallback to legacy detection
                    logger.info("üîÑ Using legacy multi-invoice detection")
                    multi_invoice_detected = is_actual_multi_invoice(raw_text)
                    
                # Additional validation: only treat as multi-invoice if we have strong evidence
                if multi_invoice_detected:
                    logger.info("üîç Multi-invoice detected, performing additional validation...")
                    
                    # Count unique invoice numbers in the text using conservative patterns
                    invoice_patterns = [
                        r"\b(?:invoice|inv)\s*(?:no\.?|number|#)?\s*[:\-]?\s*([A-Za-z0-9\-]{3,})",
                        r"\binvoice\s*#\s*([A-Za-z0-9\-]{3,})",
                    ]
                    
                    unique_invoices = set()
                    for pattern in invoice_patterns:
                        matches = re.findall(pattern, raw_text, flags=re.IGNORECASE)
                        for match in matches:
                            cleaned = match.strip()
                            if cleaned and len(cleaned) >= 3:
                                unique_invoices.add(cleaned)
                    
                    logger.info(f"üîç Found {len(unique_invoices)} unique invoice numbers: {unique_invoices}")
                    
                    # Only proceed if we have at least 1 distinct invoice number (changed from 2)
                    if len(unique_invoices) < 1:
                        logger.info(f"‚ö†Ô∏è Multi-invoice detection overridden: only {len(unique_invoices)} explicit invoice numbers found")
                        multi_invoice_detected = False
                    
                    # Additional check: if this is a single-page document, be extra conservative
                    if detection_result and detection_result.context_analysis and detection_result.context_analysis.page_count <= 1:
                        logger.info(f"‚ö†Ô∏è Single-page document detected ({detection_result.context_analysis.page_count} pages), forcing single-invoice mode")
                        multi_invoice_detected = False
                    
                    # Final check: if we have less than 50 words, it's probably a single invoice (changed from 100)
                    if len(raw_text.split()) < 50:
                        logger.info(f"‚ö†Ô∏è Document too short ({len(raw_text.split())} words), forcing single-invoice mode")
                        multi_invoice_detected = False
                    
                    # Final validation: if we still think it's multi-invoice, log the decision
                    if multi_invoice_detected:
                        logger.info("‚úÖ Multi-invoice detection confirmed after validation")
                        
                        # Handle multi-invoice processing
                        if detection_result and detection_result.detected_invoices:
                            # Use unified detection results
                            invoices = []
                            try:
                                from db_manager import save_invoice_to_db
                            except Exception as e:
                                logger.error(f"‚ùå Could not import save_invoice_to_db: {e}")
                                save_invoice_to_db = None
                            for i, detected_invoice in enumerate(detection_result.detected_invoices):
                                invoice_id = str(uuid.uuid4())
                                # Extract data for this invoice
                                part_text = detected_invoice.get('context', '')
                                part_extracted = extract_invoice_data_from_text(part_text)
                                # Normalize confidence to 0-100 for UI, but store raw 0-1 in DB
                                det_conf = detection_result.confidence or 0.0
                                raw_conf_0_1 = det_conf if det_conf <= 1.0 else min(1.0, det_conf / 100.0)
                                ui_conf_0_100 = min(100.0, max(30.0, raw_conf_0_1 * 100.0))  # Minimum 30% confidence
                                # Persist to DB if possible
                                if save_invoice_to_db:
                                    try:
                                        save_invoice_to_db(
                                            invoice_id=invoice_id,
                                            supplier_name=part_extracted.get("supplier_name", "Unknown Supplier"),
                                            invoice_number=detected_invoice.get('invoice_number', f"INV-{i+1:03d}"),
                                            invoice_date=part_extracted.get("invoice_date", datetime.now().strftime("%Y-%m-%d")),
                                            total_amount=part_extracted.get("total_amount", 0.0),
                                            confidence=raw_conf_0_1,  # store 0-1 internally
                                            ocr_text=part_text,
                                            line_items=[]
                                        )
                                    except Exception as db_err:
                                        logger.error(f"‚ùå Failed saving sub-invoice: {db_err}")
                                invoices.append({
                                    "invoice_id": invoice_id,
                                    "supplier_name": part_extracted.get("supplier_name", "Unknown Supplier"),
                                    "invoice_number": detected_invoice.get('invoice_number', f"INV-{i+1:03d}"),
                                    "invoice_date": part_extracted.get("invoice_date", datetime.now().strftime("%Y-%m-%d")),
                                    "total_amount": part_extracted.get("total_amount", 0.0),
                                    "confidence": ui_conf_0_100,
                                    "page_range": detected_invoice.get('page_range', f"Page {i+1}"),
                                    "invoice_text": part_text,
                                    "page_numbers": detected_invoice.get('page_numbers', [i+1]),
                                    "metadata": {
                                        "supplier_name": part_extracted.get("supplier_name", "Unknown Supplier"),
                                        "invoice_number": detected_invoice.get('invoice_number', f"INV-{i+1:03d}"),
                                        "invoice_date": part_extracted.get("invoice_date", datetime.now().strftime("%Y-%m-%d")),
                                        "total_amount": part_extracted.get("total_amount", 0.0),
                                        "confidence": ui_conf_0_100
                                    },
                                    "line_items": []
                                })
                            if invoices and len(invoices) >= 1:  # Changed from 2 to 1
                                logger.info(f"‚úÖ Returning {len(invoices)} multi-invoice results")
                                return {
                                    "message": f"Multi-invoice document processed successfully using unified detection",
                                    "data": {
                                        "saved_invoices": invoices,
                                        "total_invoices": len(invoices)
                                    },
                                    "saved_invoices": invoices,
                                    "total_invoices": len(invoices),
                                    "original_filename": file.filename,
                                    "detection_confidence": detection_result.confidence if detection_result else 0.0
                                }
                            else:
                                logger.info("‚ö†Ô∏è Only one valid sub-invoice extracted; treating as single invoice")
                                multi_invoice_detected = False
                        else:
                            logger.info("‚ö†Ô∏è Multi-invoice detection overridden by validation checks")
                
            except Exception as e:
                logger.error(f"‚ùå Multi-invoice detection failed: {e}")
                multi_invoice_detected = False
        
        # Save to database regardless of OCR method used
        try:
            from db_manager import save_invoice_to_db, save_uploaded_file_to_db
            
            # Save uploaded file record
            save_uploaded_file_to_db(
                file_id=file_id,
                original_filename=file.filename,
                file_path=str(file_path),
                file_type=ocr_data["document_type"],
                confidence=ocr_data["confidence"]
            )
            
            # Save invoice data if it's an invoice
            if ocr_data["document_type"] == "invoice":
                logger.info(f"üíæ Upload endpoint - Saving invoice to database: {file_id}")
                save_invoice_to_db(
                    invoice_id=file_id,
                    supplier_name=ocr_data["supplier_name"],
                    invoice_number=ocr_data["invoice_number"],
                    invoice_date=ocr_data["invoice_date"],
                    total_amount=ocr_data["total_amount"],
                    confidence=ocr_data["confidence"],
                    ocr_text=ocr_data["raw_text"],
                    line_items=ocr_data["line_items"]
                )
                logger.info(f"‚úÖ Upload endpoint - Invoice saved to database: {file_id}")
        except Exception as db_error:
            logger.error(f"‚ùå Upload endpoint - Database save failed: {db_error}")
        
        # Return processed invoice data with CORRECT STRUCTURE for frontend
        # Normalize confidence to 0-1 range for frontend
        confidence_raw = ocr_data.get("confidence", 0.0)
        
        # Handle different confidence formats and ensure proper normalization
        if isinstance(confidence_raw, (int, float)):
            if confidence_raw > 1.0:
                # If confidence is already a percentage, keep in 0-100 for UI layer
                confidence_normalized = min(100.0, float(confidence_raw))
            else:
                # Convert 0-1 to 0-100 for UI layer
                confidence_normalized = min(100.0, max(30.0, float(confidence_raw) * 100.0))
        else:
            # Fallback for string or invalid values
            try:
                val = float(confidence_raw)
                confidence_normalized = val if val > 1.0 else val * 100.0
            except (ValueError, TypeError):
                confidence_normalized = 30.0  # Default minimum confidence in percent
        
        # Ensure confidence is never 0% or > 100%
        confidence_normalized = max(30.0, min(95.0, confidence_normalized))
        
        logger.info(f"üîç Confidence calculation: raw={confidence_raw}, normalized%={confidence_normalized:.1f}")
        
        # ‚úÖ FINAL CHECK: Ensure we never return multi-invoice for single invoices
        if multi_invoice_detected:
            logger.warning("‚ö†Ô∏è Multi-invoice detection was triggered but validation failed - forcing single invoice mode")
            multi_invoice_detected = False
        
        logger.info(f"‚úÖ Final result: single invoice mode, confidence={confidence_normalized:.1f}%")
        
        return {
            "success": True,
            "message": "Invoice processed successfully",
            "invoice_id": ocr_data.get("file_id", file_id),
            "filename": filename,
            "original_name": file.filename,
            "status": "processed",
            "upload_timestamp": datetime.now().isoformat(),
            "word_count": ocr_data["word_count"],
            "raw_ocr_text": ocr_data["raw_text"],
            "line_items": ocr_data["line_items"],
            "document_type": ocr_data["document_type"],
            # ‚úÖ CRITICAL: Nest data under data as frontend expects
            "data": {
                "confidence": confidence_normalized,
                "supplier_name": ocr_data["supplier_name"],
                "invoice_number": ocr_data["invoice_number"],
                "total_amount": ocr_data["total_amount"],
                "invoice_date": ocr_data["invoice_date"]
            },
            "parsed_data": {
                "confidence": confidence_normalized,
                "supplier_name": ocr_data["supplier_name"],
                "invoice_number": ocr_data["invoice_number"],
                "total_amount": ocr_data["total_amount"],
                "invoice_date": ocr_data["invoice_date"]
            }
        }
        
    except Exception as e:
        logger.error(f"‚ùå Upload failed: {e}")
        raise HTTPException(status_code=500, detail=f"Upload failed: {str(e)}")

# Add bulletproof ingestion endpoint
@app.post("/api/upload-bulletproof")
async def upload_file_bulletproof(file: UploadFile = File(...)):
    """
    Upload file using bulletproof ingestion v3 system
    
    This endpoint uses the comprehensive ingestion system that can handle:
    - Multiple invoices in one file
    - Split documents across multiple files
    - Out-of-order pages
    - Duplicate detection
    - Cross-file stitching
    - Document classification
    """
    if not BULLETPROOF_INGESTION_AVAILABLE:
        raise HTTPException(status_code=503, detail="Bulletproof ingestion system not available")
    
    try:
        logger.info(f"üöÄ Starting bulletproof ingestion for: {file.filename}")
        
        # Save uploaded file
        file_id = str(uuid.uuid4())
        file_path = upload_dir / f"{file_id}_{file.filename}"
        
        with open(file_path, "wb") as buffer:
            content = await file.read()
            buffer.write(content)
        
        logger.info(f"üíæ File saved to: {file_path}")
        
        # Prepare file data for bulletproof ingestion
        file_data = {
            'id': file_id,
            'file_path': str(file_path),
            'filename': file.filename,
            'file_size': len(content),
            'upload_time': datetime.now(),
            'images': [],
            'ocr_texts': []
        }
        
        # Process file to extract images and OCR text
        try:
            from ocr.unified_ocr_engine import get_unified_ocr_engine
            unified_engine = get_unified_ocr_engine()
            
            # Get images from the file
            images = await unified_engine.extract_images_from_file(str(file_path))
            file_data['images'] = images
            
            # Get OCR text for each image
            ocr_texts = []
            for i, image in enumerate(images):
                try:
                    # Use unified engine to get OCR text
                    text_result = await unified_engine.extract_text_from_image(image)
                    ocr_texts.append(text_result.get('text', ''))
                except Exception as e:
                    logger.warning(f"Failed to extract OCR text from image {i}: {e}")
                    ocr_texts.append('')
            
            file_data['ocr_texts'] = ocr_texts
            
        except Exception as e:
            logger.error(f"Failed to process file for bulletproof ingestion: {e}")
            # Fallback to basic processing
            file_data['images'] = []
            file_data['ocr_texts'] = ['']
        
        # Process with bulletproof ingestion
        files_to_process = [file_data]
        intake_result = intake_router.process_upload(files_to_process)
        
        if not intake_result.success:
            raise HTTPException(status_code=500, detail=f"Bulletproof ingestion failed: {intake_result.errors}")
        
        # Convert canonical entities to response format
        response_data = {
            'success': True,
            'file_id': file_id,
            'filename': file.filename,
            'processing_time': intake_result.processing_time,
            'canonical_invoices': [],
            'canonical_documents': [],
            'duplicate_groups': [],
            'stitch_groups': [],
            'warnings': intake_result.warnings,
            'metadata': intake_result.metadata
        }
        
        # Convert canonical invoices
        for invoice in intake_result.canonical_invoices:
            response_data['canonical_invoices'].append({
                'id': invoice.canonical_id,
                'supplier_name': invoice.supplier_name,
                'invoice_number': invoice.invoice_number,
                'invoice_date': invoice.invoice_date,
                'currency': invoice.currency,
                'subtotal': invoice.subtotal,
                'tax': invoice.tax,
                'total_amount': invoice.total_amount,
                'confidence': invoice.confidence,
                'field_confidence': invoice.field_confidence,
                'warnings': invoice.warnings,
                'source_segments': invoice.source_segments,
                'source_pages': invoice.source_pages
            })
        
        # Convert canonical documents
        for document in intake_result.canonical_documents:
            response_data['canonical_documents'].append({
                'id': document.canonical_id,
                'doc_type': document.doc_type,
                'supplier_name': document.supplier_name,
                'document_number': document.document_number,
                'document_date': document.document_date,
                'confidence': document.confidence,
                'source_segments': document.source_segments,
                'source_pages': document.source_pages
            })
        
        # Convert duplicate groups
        for dup_group in intake_result.duplicate_groups:
            response_data['duplicate_groups'].append({
                'id': dup_group.group_id,
                'duplicate_type': dup_group.duplicate_type,
                'primary_id': dup_group.primary_id,
                'duplicates': dup_group.duplicates,
                'confidence': dup_group.confidence,
                'reasons': dup_group.reasons
            })
        
        # Convert stitch groups
        for stitch_group in intake_result.stitch_groups:
            response_data['stitch_groups'].append({
                'id': stitch_group.group_id,
                'confidence': stitch_group.confidence,
                'doc_type': stitch_group.doc_type,
                'supplier_guess': stitch_group.supplier_guess,
                'invoice_numbers': stitch_group.invoice_numbers,
                'dates': stitch_group.dates,
                'reasons': stitch_group.reasons,
                'segment_count': len(stitch_group.segments)
            })
        
        logger.info(f"‚úÖ Bulletproof ingestion completed: {len(response_data['canonical_invoices'])} invoices, {len(response_data['canonical_documents'])} documents")
        
        return response_data
        
    except Exception as e:
        logger.error(f"‚ùå Bulletproof ingestion failed: {e}")
        raise HTTPException(status_code=500, detail=str(e))

# Basic API endpoints for testing
@app.get("/api/invoices")
async def get_invoices():
    try:
        from db_manager import get_all_invoices
        invoices = get_all_invoices()
        return {"invoices": invoices}
    except Exception as e:
        logger.error(f"‚ùå Failed to get invoices: {e}")
        return {"invoices": []}

@app.get("/api/delivery-notes")
async def get_delivery_notes():
    try:
        from db_manager import get_all_delivery_notes
        delivery_notes = get_all_delivery_notes()
        return {"delivery_notes": delivery_notes}
    except Exception as e:
        logger.error(f"‚ùå Failed to get delivery notes: {e}")
        return {"delivery_notes": []}

@app.get("/api/files")
async def get_files():
    try:
        from db_manager import get_all_uploaded_files
        files = get_all_uploaded_files()
        return {"files": files}
    except Exception as e:
        logger.error(f"‚ùå Failed to get files: {e}")
        return {"files": []} 